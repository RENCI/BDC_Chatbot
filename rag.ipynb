{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitbookLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from fastapi import FastAPI\n",
    "# from langserve import add_routes\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "\n",
    "from typing import AsyncIterator, Iterator\n",
    "\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.query_constructor.ir import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    ")\n",
    "# from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain_community.query_constructors.chroma import ChromaTranslator\n",
    "\n",
    "\n",
    "# from babel.dates import format_date, format_datetime, format_time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "set_debug(False)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  meta-llama/Meta-Llama-3.1-8B-Instruct base_url:  http://localhost:8080/v1\n",
      "model:  bge-m3 base_url:  http://localhost:11434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1423734/3045003205.py:20: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  emb = OllamaEmbeddings(base_url=EMBEDDING_URL, model=EMBEDDING_MODEL, temperature=0)\n"
     ]
    }
   ],
   "source": [
    "def init_vars(retriever_top_k = 5):\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    COMPLETION_URL = os.getenv(\"COMPLETION_URL\")\n",
    "    COMPLETION_MODEL = os.getenv(\"COMPLETION_MODEL\")\n",
    "    EMBEDDING_URL = os.getenv(\"EMBEDDING_URL\")\n",
    "    EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "    DB_PATH = os.getenv(\"DB_PATH\")\n",
    "\n",
    "\n",
    "    if COMPLETION_URL and COMPLETION_MODEL:\n",
    "        llm = ChatOpenAI(base_url=COMPLETION_URL, model=COMPLETION_MODEL, temperature=0)\n",
    "        print(\"model: \", COMPLETION_MODEL, \"base_url: \", COMPLETION_URL)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "        print(\"model: gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "    if EMBEDDING_URL and EMBEDDING_MODEL:\n",
    "        emb = OllamaEmbeddings(base_url=EMBEDDING_URL, model=EMBEDDING_MODEL, temperature=0)\n",
    "        print(\"model: \", EMBEDDING_MODEL, \"base_url: \", EMBEDDING_URL)\n",
    "    else:\n",
    "        emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        print(\"model: text-embedding-3-small\")\n",
    "\n",
    "    \n",
    "\n",
    "    vectorstore = Chroma(persist_directory=DB_PATH,embedding_function=emb)\n",
    "\n",
    "    default_retriever = vectorstore.as_retriever(search_kwargs = {\"k\": retriever_top_k})\n",
    "\n",
    "    return llm, emb, vectorstore, default_retriever, retriever_top_k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rag_chain_constructor(retriever):\n",
    "    \n",
    "\n",
    "    contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    # history_aware_retriever = create_history_aware_retriever(\n",
    "    #     ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\"), retriever, contextualize_q_prompt\n",
    "    # )\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    qa_system_prompt = \"\"\"You are an assistant, called \"BioData Catalyst(BDC) Assistant\", for question-answering tasks related BioData Catalyst. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you can't get an answer base on the context, just say that you don't know. \\\n",
    "Use 1-3 sentences and keep the answer concise, unless otherwise specified.\\\n",
    "The context are retrieved based on the user query and the chat history.\\\n",
    "If there is context provided, answer the question based on the context.\\\n",
    "\n",
    "### context: {context}\"\"\"\n",
    "    \n",
    "    qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", qa_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # question_answer_chain = create_stuff_documents_chain(ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\"), qa_prompt)\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    \n",
    "    \n",
    "    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "\n",
    "llm, emb, vectorstore, default_retriever, retriever_top_k = init_vars(retriever_top_k=5)\n",
    "\n",
    "\n",
    "default_rag_chain = rag_chain_constructor(default_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(answer, context) -> str:\n",
    "\n",
    "    output = answer\n",
    "    docs = context\n",
    "    \n",
    "    sources = []\n",
    "    titles = []\n",
    "    contents = []\n",
    "    for doc in docs:\n",
    "        source = doc.metadata[\"file_path\"]\n",
    "        \n",
    "        if not source in sources:\n",
    "            sources.append(source)\n",
    "            titles.append(f\"{doc.metadata['doc_type']}: {doc.metadata['file_path']}\")\n",
    "            contents.append(doc.page_content)\n",
    "\n",
    "\n",
    "    if len(sources) == 1:\n",
    "        output += \"\\n\\n#### Source:\\n\"\n",
    "    elif len(sources) > 1:\n",
    "        output += \"\\n\\n#### Sources:\\n\"\n",
    "\n",
    "    for i, source in enumerate(sources):\n",
    "        output += f\"{i + 1}. [{titles[i]}]({source})\\n\"\n",
    "        output += f\"{contents[i]}\\n\\n\\n\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the latest update?',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(metadata={'date': '2024-03-13', 'display_date': 'March 13, 2024', 'file_path': 'interim-bdc-website/src/data/events/2024-03-13_Community-Hours.mdx', 'forum_post': 'https://bdcatalyst.freshdesk.com/support/discussions/topics/60000407674', 'location': 'Virtual via Zoom', 'path': '/events/2024-03-13/community_hours', 'registration_required': True, 'tags': 'community hours', 'time': '1:00 - 2:00 pm ET', 'title': 'BDC March Community Hours', 'url': 'https://renci.zoom.us/webinar/register/2117093062319/WN_qWm4svX0T36KwiIAO-mORA'}, page_content='Join us on Wednesday, March 13 1pm ET for a data update on BDC with Sweta Ladwa, Chief, Scientific Solutions Delivery Branch, NHLBI.\\n\\nEven if you cannot attend the session live, you can still\\xa0[register](https://renci.zoom.us/webinar/register/2117093062319/WN_qWm4svX0T36KwiIAO-mORA)\\xa0to have the session recording and slides sent to you post-event.\\n\\nAll users are invited to attend, whether you are new to BDC or have been using it for some time. If you are not yet registered for the ecosystem, we welcome you to\\xa0[join our community](/join-bdc/).\\n\\nMake sure to\\xa0[register now](https://renci.zoom.us/webinar/register/2117093062319/WN_qWm4svX0T36KwiIAO-mORA)\\xa0- we look forward to seeing you!\\n\\n### What are Community Hours?\\n\\nBDC Community Hours is a monthly, hour-long event where users can learn about features of the ecosystem. The hour is split into time for presentation by a platform team and time for questions. Teams will showcase tools, new features, or tips that meet user needs. After the presentations, time is available for discussion and questions for platform reps from users.'),\n",
       "  Document(metadata={'date': '2021-12-08', 'display_date': 'December 8, 2021', 'file_path': 'interim-bdc-website/src/data/events/2021-12-08_Community-Hours.mdx', 'forum_post': 'https://bdcatalyst.freshdesk.com/support/discussions/topics/60000406736', 'location': '', 'path': '/events/2021-12-08/community_hours', 'tags': 'community hours, ecosystem, research', 'time': '1:00 - 2:00 pm EDT', 'title': 'NHLBI BioData Catalyst Community Hours: Ecosystem and Research Highlights', 'url': 'https://bit.ly/3H9J1Fi'}, page_content='Join us on Wednesday, December 8th from 1:00 pm - 2:00 pm EST for our final BioData Catalyst Community Hours of 2021: Ecosystem and Research Highlights. This informal, [virtual event](https://bit.ly/3H9J1Fi) will have an exciting and conversational agenda:\\n\\n- Democratizing Data: Studies available on BioData Catalyst, including updates from Gen3 and PIC-SURE\\n\\n- Democratizing Analysis: Workflows shared by the community to date, with highlights from Dockstore, Seven Bridges, and Terra\\n\\n- Accelerating Precision Medicine and Research: Hear about studies and presentations citing BioData Catalyst, as well as updates from Fellows; listen to what users have accomplished on the ecosystem so far, and what hopes they have for the future\\n\\n- Building a Community: How we have been - and will continue to be - a community-centric endeavor, with outreach events, conferences, new users, and new consortia\\n\\nAs always, time will be available for discussion and to address questions, challenges, and issues you might be facing in the ecosystem.\\n\\nAll users are invited to attend, whether you are new to BioData Catalyst or have been using it for some time. If you are not yet registered for the ecosystem, we welcome you to [join our community](/join-bdc).\\n\\nYou are welcome to anonymously include your [questions in advance](https://forms.gle/gvpqntUrPwXin6qA9) or bring your discussion topics to the session live. \\n\\nMake sure to [register now](https://bit.ly/3H9J1Fi) - we look forward to seeing you!\\n\\n### What are Community Hours?\\n\\nBioData Catalyst Community Hours is a monthly, hour-long event where users can learn about features of the ecosystem. The hour is split into time for presentation by a platform team and time for questions. Teams will showcase tools, new features, or tips that meet user needs. After the presentations, time is available for discussion and questions for platform reps from users.'),\n",
       "  Document(metadata={'date': '2022-08-16', 'display_date': 'August 16th, 2022', 'file_path': 'interim-bdc-website/src/data/events/2022-08-16_Cross-Data_Harmonization_Interest_Group.mdx', 'location': 'Zoom (no registration required)', 'path': '/events/2022-08-16/interest-groups/cross-data-harmonization', 'tags': 'interest groups, cross-data harmonization', 'time': '1:00 - 2:00 p.m. EDT', 'title': 'NHLBI BioData Catalyst Cross-Data Harmonization Interest Group', 'url': 'https://renci.zoom.us/j/92679200774?pwd=VzhoQithMERENzVWakR2Ym5Rd0tydz09'}, page_content='*This group meets every third Tuesday of the month, from 1:00 - 2:00 p.m. ET. Registration is not necessary; use the Zoom link or meeting details to join.*\\n\\nGoals: Provide a platform for fellows to discuss the pain points for phenotype harmonization and Q&A from experts. Establish environments of sharing harmonized phenotype data/pipelines by fellows and facilitating developing/publishing harmonizing workflow.\\n\\n**Zoom Link *(No Registration Required)*:** [August 16th, 2022 at 1:00 p.m. ET](https://renci.zoom.us/j/92679200774?pwd=VzhoQithMERENzVWakR2Ym5Rd0tydz09)\\n- **Meeting ID:** 926 7920 0774\\n- **Passcode:** BDCatalyst'),\n",
       "  Document(metadata={'date': '2022-05-17', 'display_date': 'May 17, 2022', 'file_path': 'interim-bdc-website/src/data/events/2022-05-17_Cross-Data_Harmonization_Interest_Group.mdx', 'location': 'Zoom (no registration required)', 'path': '/events/2022-05-17/interest-groups/cross-data-harmonization', 'tags': 'interest groups, cross-data harmonization', 'time': '1:00 - 2:00 p.m. EDT', 'title': 'NHLBI BioData Catalyst Cross-Data Harmonization Interest Group', 'url': 'https://renci.zoom.us/j/92679200774?pwd=VzhoQithMERENzVWakR2Ym5Rd0tydz09'}, page_content='*This group meets every third Tuesday of the month, from 1:00 - 2:00 p.m. ET. Registration is not necessary; use the Zoom link or meeting details to join.*\\n\\nGoals: Provide a platform for fellows to discuss the pain points for phenotype harmonization and Q&A from experts. Establish environments of sharing harmonized phenotype data/pipelines by fellows and facilitating developing/publishing harmonizing workflow.\\n\\n**Zoom Link *(No Registration Required)*:** [May 17th, 2022 at 1:00 p.m. ET](https://renci.zoom.us/j/92679200774?pwd=VzhoQithMERENzVWakR2Ym5Rd0tydz09)\\n- **Meeting ID:** 926 7920 0774\\n- **Passcode:** BDCatalyst'),\n",
       "  Document(metadata={'date': '2024-09-18', 'display_date': 'Wednesday, September 18, 2024', 'externalEvent': False, 'file_path': 'interim-bdc-website/src/data/events/2024-09-18_Community-Hours.mdx', 'forum_post': 'https://bdcatalyst.freshdesk.com/support/discussions/topics/60000407862', 'location': 'Zoom', 'path': '/events/2024-09-18/community_hours', 'registration_required': True, 'tags': 'community hours, sickle cell disease', 'time': '1:00 - 2:00 pm ET', 'title': 'September Community Hours: Sickle Cell Data on BDC', 'url': 'https://renci.zoom.us/webinar/register/8017241872334/WN_GjMhxs7rQNOyQWZgiygS8w'}, page_content=\"Register to hear about NHLBI's sickle cell disease work, the Sickle Cell Disease Implementation Consortium, its patient registry, the data it collects, and the availability of the data in BDC and the emerging research into Sickle Cell in Hispanic populations.\\n\\n### What are Community Hours?\\n\\nBDC Community Hours is a monthly, hour-long event where users can learn about features of the ecosystem. The hour is split into time for presentation by a platform team and time for questions. Teams will showcase tools, new features, or tips that meet user needs. After the presentations, time is available for discussion and questions for platform reps from users.\\n\\nEven if you cannot attend the session live, you can still [register](https://renci.zoom.us/webinar/register/8017241872334/WN_GjMhxs7rQNOyQWZgiygS8w) to have the session recording and slides sent to you post-event.\\n\\nAll users are invited to attend, whether you are new to BDC or have been using it for some time. If you are not yet registered for the ecosystem, we welcome you to [join our community](/join-bdc/).\\n\\nMake sure to [register now](https://renci.zoom.us/webinar/register/8017241872334/WN_GjMhxs7rQNOyQWZgiygS8w) - we look forward to seeing you!\")],\n",
       " 'answer': 'The latest update is a data update on BioData Catalyst with Sweta Ladwa, Chief, Scientific Solutions Delivery Branch, NHLBI, scheduled for Wednesday, March 13 at 1pm ET.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the latest update?\"\n",
    "\n",
    "default_rag_chain.invoke({\"input\": prompt, \"chat_history\": []})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
