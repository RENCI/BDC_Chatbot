{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from typing import AsyncIterator, Iterator\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import chromadb\n",
    "import uuid\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  bge-m3 base_url:  http://localhost:11434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1626717/3686844393.py:11: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  emb = OllamaEmbeddings(base_url=EMBEDDING_URL, model=EMBEDDING_MODEL, show_progress=True)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "EMBEDDING_URL = os.getenv(\"EMBEDDING_URL\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "DB_PATH = os.getenv(\"DB_PATH\")\n",
    "\n",
    "shutil.rmtree(DB_PATH, ignore_errors=True)\n",
    "\n",
    "\n",
    "if EMBEDDING_URL and EMBEDDING_MODEL:\n",
    "    emb = OllamaEmbeddings(base_url=EMBEDDING_URL, model=EMBEDDING_MODEL, show_progress=True)\n",
    "    print(\"model: \", EMBEDDING_MODEL, \"base_url: \", EMBEDDING_URL)\n",
    "else:\n",
    "    emb = OpenAIEmbeddings(model=\"text-embedding-3-small\", show_progress_bar=True)\n",
    "    print(\"model: text-embedding-3-small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class pklLoader(BaseLoader):\n",
    "#     def __init__(self, file_path: str, doc_type: str = None) -> None:\n",
    "#         self.file_path = file_path\n",
    "#         self.doc_type = doc_type\n",
    "\n",
    "    \n",
    "#     def lazy_load(self) -> Iterator[Document]:  # <-- Does not take any arguments\n",
    "#         # Load the data from the file\n",
    "#         # df = pd.read_pickle(self.file_path)\n",
    "#         with open(self.file_path, 'rb') as f:\n",
    "#             pkl_list = pickle.load(f)\n",
    "        \n",
    "#         for i, row in pkl_list:\n",
    "#             yield Document(\n",
    "#                 page_content=row['content'],\n",
    "#                 metadata=row['metadata'],\n",
    "#                 doc_type=self.doc_type\n",
    "#                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_vectorstore(docs_path, db_path = \".chroma_db/\"):\n",
    "#     all_docs = []\n",
    "#     file_name_list = ['events.pkl', 'latest_updates.pkl', 'fellows.pkl', 'pages.pkl']\n",
    "#     doc_type_list = ['event', 'update', 'fellow', 'page']\n",
    "#     for file_name, doc_type in zip(file_name_list, doc_type_list):\n",
    "#         loader = pklLoader(os.path.join(docs_path, file_name), doc_type)\n",
    "#         all_docs.extend(loader.load())\n",
    "#     print(\"Number of documents: \", len(all_docs))\n",
    "#     return Chroma.from_documents(all_docs, emb, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPKL(file_path, doc_type):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        pkl_list = pickle.load(f)\n",
    "    page_contents = [row['content'] for row in pkl_list]\n",
    "    metadata = [dict(row['metadata'], doc_type=doc_type) for row in pkl_list]\n",
    "    \n",
    "    embeddings = emb.embed_documents(page_contents)\n",
    "    return page_contents, metadata, embeddings\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_client(docs_path, db_path = \".chroma_db/\"):\n",
    "    file_name_list = ['events.pkl', 'latest_updates.pkl', 'fellows.pkl', 'pages.pkl']\n",
    "    doc_type_list = ['event', 'update', 'fellow', 'page']\n",
    "    \n",
    "    all_contents = []\n",
    "    all_metadatas = []\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for file_name, doc_type in zip(file_name_list, doc_type_list):\n",
    "        print(\"Loading \", doc_type)\n",
    "        page_contents, metadata, embeddings = loadPKL(os.path.join(docs_path, file_name), doc_type)\n",
    "        all_contents.extend(page_contents)\n",
    "        all_metadatas.extend(metadata)\n",
    "        all_embeddings.extend(embeddings)\n",
    "    \n",
    "    for metadata in all_metadatas:\n",
    "        if len(metadata) == 0:\n",
    "            metadata = None\n",
    "    \n",
    "    all_ids = [str(uuid.uuid4()) for _ in range(len(all_contents))]\n",
    "    \n",
    "    persistent_client = chromadb.PersistentClient(path=db_path)\n",
    "    collection = persistent_client.get_or_create_collection(\"langchain\")\n",
    "    collection.add(ids=all_ids, documents=all_contents, embeddings=all_embeddings, metadatas=all_metadatas)\n",
    "    \n",
    "    \n",
    "    return persistent_client\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  event\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 45/45 [00:37<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  update\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 8/8 [00:05<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  fellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 47/47 [00:28<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "chroma_client = create_chroma_client(docs_path=\"data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
